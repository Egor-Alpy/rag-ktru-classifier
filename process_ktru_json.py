import time
import json
import numpy as np
import argparse
from tqdm import tqdm
import logging
import re
from collections import defaultdict
from qdrant_client import QdrantClient
from qdrant_client.http import models as rest
from embedding import generate_embedding, generate_batch_embeddings
from config import (
    QDRANT_HOST, QDRANT_PORT, QDRANT_COLLECTION, VECTOR_SIZE,
    BATCH_SIZE
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_ktru_data_from_json(json_file_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ö–¢–†–£ –∏–∑ JSON-—Ñ–∞–π–ª–∞"""
    try:
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ö–¢–†–£ –∏–∑ —Ñ–∞–π–ª–∞: {json_file_path}")
        with open(json_file_path, 'r', encoding='utf-8') as f:
            ktru_data = json.load(f)
        logger.info(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(ktru_data)}")
        return ktru_data
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON-—Ñ–∞–π–ª–∞: {e}")
        return None


def extract_category_from_code(ktru_code):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –ö–¢–†–£ –∫–æ–¥–∞"""
    if not ktru_code:
        return None

    # –ö–¢–†–£ –∫–æ–¥ –∏–º–µ–µ—Ç —Ñ–æ—Ä–º–∞—Ç XX.XX.XX.XXX-XXXXXXXX
    parts = ktru_code.split('-')[0].split('.')
    if len(parts) >= 2:
        return f"{parts[0]}.{parts[1]}"
    return None


def normalize_text(text):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞"""
    if not text:
        return ""

    text = text.lower()
    # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –æ–¥–Ω–∏–º
    text = re.sub(r'\s+', ' ', text)
    # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –æ—Å—Ç–∞–≤–ª—è—è –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –æ—Å–Ω–æ–≤–Ω—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
    text = re.sub(r'[^\w\s\-.,;:()]', ' ', text)
    return text.strip()


def extract_keywords_from_title(title):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"""
    if not title:
        return []

    normalized = normalize_text(title)
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ –¥–ª–∏–Ω–Ω–µ–µ 2 —Å–∏–º–≤–æ–ª–æ–≤
    words = re.findall(r'\b[–∞-—è—ëa-z0-9]{3,}\b', normalized, re.IGNORECASE)

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    stop_words = {'–¥–ª—è', '–∏–ª–∏', '–ø–æ–¥', '–Ω–∞–¥', '–≤—Å–µ', '–ø—Ä–∏', '–±–µ–∑'}
    keywords = [w for w in words if w not in stop_words]

    return keywords


def prepare_ktru_text_optimized(ktru_entry):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å —É–ø–æ—Ä–æ–º –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ"""
    text_parts = []

    # –ù–ê–ó–í–ê–ù–ò–ï - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç
    title = ktru_entry.get('title', '')
    if title:
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤–µ—Å–∞
        text_parts.append(f"–Ω–∞–∑–≤–∞–Ω–∏–µ: {title}")
        text_parts.append(f"—Ç–æ–≤–∞—Ä: {title}")

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
        keywords = extract_keywords_from_title(title)
        if keywords:
            text_parts.append(f"–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {' '.join(keywords)}")

    # –ö–æ–¥ –ö–¢–†–£ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è
    ktru_code = ktru_entry.get('ktru_code', '')
    if ktru_code:
        text_parts.append(f"–∫–æ–¥ –ö–¢–†–£: {ktru_code}")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        category = extract_category_from_code(ktru_code)
        if category:
            text_parts.append(f"–∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")

    # –û–ø–∏—Å–∞–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    description = ktru_entry.get('description', '')
    if description and description.strip():
        # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è
        desc_normalized = normalize_text(description)
        if len(desc_normalized) > 200:
            desc_normalized = desc_normalized[:200] + "..."
        text_parts.append(f"–æ–ø–∏—Å–∞–Ω–∏–µ: {desc_normalized}")

    # –ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è
    unit = ktru_entry.get('unit', '')
    if unit and unit not in ['–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö', '']:
        text_parts.append(f"–µ–¥–∏–Ω–∏—Ü–∞: {unit}")

    # –ê—Ç—Ä–∏–±—É—Ç—ã (—Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ)
    if 'attributes' in ktru_entry and ktru_entry['attributes']:
        important_attrs = []

        for attr in ktru_entry['attributes'][:5]:  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            attr_name = attr.get('attr_name', '')

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∞—Ç—Ä–∏–±—É—Ç–∞
            values = []
            if 'attr_values' in attr and attr['attr_values']:
                for val in attr['attr_values'][:3]:  # –ú–∞–∫—Å–∏–º—É–º 3 –∑–Ω–∞—á–µ–Ω–∏—è
                    value_text = val.get('value', '')
                    if value_text:
                        values.append(value_text)
            elif 'attr_value' in attr:
                values.append(attr['attr_value'])

            if values and attr_name:
                attr_text = f"{attr_name}: {', '.join(values)}"
                important_attrs.append(attr_text)

        if important_attrs:
            text_parts.append(f"—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {'; '.join(important_attrs)}")

    # –°–æ–∑–¥–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ matching
    if title:
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è
        title_words = title.split()
        if len(title_words) > 2:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª–æ–≤–∞
            text_parts.append(f"–Ω–∞—á–∞–ª–æ: {' '.join(title_words[:2])}")
            text_parts.append(f"–∫–æ–Ω–µ—Ü: {' '.join(title_words[-2:])}")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏
    full_text = ' | '.join(text_parts)

    return full_text


def create_search_index(ktru_data):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º"""
    search_index = {
        'by_keyword': defaultdict(list),
        'by_category': defaultdict(list),
        'by_code': {},
        'full_data': {}
    }

    for idx, entry in enumerate(ktru_data):
        ktru_code = entry.get('ktru_code', '')
        title = entry.get('title', '')

        # –ò–Ω–¥–µ–∫—Å –ø–æ –∫–æ–¥—É
        search_index['by_code'][ktru_code] = idx
        search_index['full_data'][ktru_code] = entry

        # –ò–Ω–¥–µ–∫—Å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        category = extract_category_from_code(ktru_code)
        if category:
            search_index['by_category'][category].append(ktru_code)

        # –ò–Ω–¥–µ–∫—Å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        keywords = extract_keywords_from_title(title)
        for keyword in keywords:
            search_index['by_keyword'][keyword].append(ktru_code)

    logger.info(f"–°–æ–∑–¥–∞–Ω –ø–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å: {len(search_index['by_keyword'])} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, "
                f"{len(search_index['by_category'])} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

    return search_index


def setup_qdrant_collection():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ Qdrant —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    try:
        qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è
        collections = qdrant_client.get_collections().collections
        collection_names = [collection.name for collection in collections]

        if QDRANT_COLLECTION not in collection_names:
            logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {QDRANT_COLLECTION} –≤ Qdrant")
            qdrant_client.create_collection(
                collection_name=QDRANT_COLLECTION,
                vectors_config=rest.VectorParams(
                    size=VECTOR_SIZE,
                    distance=rest.Distance.COSINE
                ),
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞
                optimizers_config=rest.OptimizersConfigDiff(
                    default_segment_number=5,
                    indexing_threshold=20000
                )
            )
        else:
            logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {QDRANT_COLLECTION} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è —á–∏—Å—Ç–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
            response = input("–•–æ—Ç–∏—Ç–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é? (y/N): ")
            if response.lower() == 'y':
                logger.info("–£–¥–∞–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏...")
                qdrant_client.delete_collection(collection_name=QDRANT_COLLECTION)

                logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏...")
                qdrant_client.create_collection(
                    collection_name=QDRANT_COLLECTION,
                    vectors_config=rest.VectorParams(
                        size=VECTOR_SIZE,
                        distance=rest.Distance.COSINE
                    ),
                    optimizers_config=rest.OptimizersConfigDiff(
                        default_segment_number=5,
                        indexing_threshold=20000
                    )
                )

        return qdrant_client
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ Qdrant: {e}")
        return None


def process_ktru_json(json_file_path):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ö–¢–†–£ –∏–∑ JSON-—Ñ–∞–π–ª–∞"""
    start_time = time.time()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    ktru_data = load_ktru_data_from_json(json_file_path)
    if not ktru_data:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ö–¢–†–£ –∏–∑ JSON-—Ñ–∞–π–ª–∞")
        return

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    search_index = create_search_index(ktru_data)

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Qdrant
    qdrant_client = setup_qdrant_collection()
    if not qdrant_client:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Qdrant")
        return

    try:
        total_records = len(ktru_data)
        logger.info(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –ö–¢–†–£ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_records}")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞–º–∏
        batch_size = BATCH_SIZE
        processed_count = 0

        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        with tqdm(total=total_records, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –ö–¢–†–£") as pbar:
            for i in range(0, total_records, batch_size):
                batch = ktru_data[i:i + batch_size]
                batch_texts = []
                batch_ids = []

                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤
                for idx, ktru_entry in enumerate(batch):
                    text_to_embed = prepare_ktru_text_optimized(ktru_entry)
                    batch_texts.append(text_to_embed)
                    batch_ids.append(i + idx)

                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
                batch_embeddings = generate_batch_embeddings(batch_texts)

                # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ—á–µ–∫ –¥–ª—è Qdrant
                points = []
                for idx, (ktru_entry, embedding) in enumerate(zip(batch, batch_embeddings)):
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ payload
                    payload = {
                        "ktru_code": ktru_entry.get('ktru_code', ''),
                        "title": ktru_entry.get('title', ''),
                        "description": ktru_entry.get('description', ''),
                        "unit": ktru_entry.get('unit', ''),
                        "version": ktru_entry.get('version', ''),
                        "keywords": extract_keywords_from_title(ktru_entry.get('title', '')),
                        "category": extract_category_from_code(ktru_entry.get('ktru_code', '')),
                        "attributes": ktru_entry.get('attributes', []),
                        "source_link": ktru_entry.get('source_link', ''),
                        "updated_at": ktru_entry.get('updated_at', ''),
                        "_search_text": batch_texts[idx][:500]  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    }

                    points.append(rest.PointStruct(
                        id=batch_ids[idx],
                        vector=embedding.tolist(),
                        payload=payload
                    ))

                # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Qdrant
                qdrant_client.upsert(
                    collection_name=QDRANT_COLLECTION,
                    points=points
                )

                processed_count += len(batch)
                pbar.update(len(batch))

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –≤ Qdrant –¥–ª—è –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
        logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–∞...")
        try:
            # –°–æ–∑–¥–∞–µ–º payload –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–¥—É
            qdrant_client.create_payload_index(
                collection_name=QDRANT_COLLECTION,
                field_name="ktru_code",
                field_schema=rest.PayloadSchemaType.KEYWORD
            )

            # –ò–Ω–¥–µ–∫—Å –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            qdrant_client.create_payload_index(
                collection_name=QDRANT_COLLECTION,
                field_name="category",
                field_schema=rest.PayloadSchemaType.KEYWORD
            )

            logger.info("‚úÖ –ò–Ω–¥–µ–∫—Å—ã —Å–æ–∑–¥–∞–Ω—ã")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã (–≤–æ–∑–º–æ–∂–Ω–æ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç): {e}")

        elapsed_time = time.time() - start_time
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –∑–∞–ø–∏—Å–µ–π –ö–¢–†–£")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        collection_info = qdrant_client.get_collection(QDRANT_COLLECTION)
        count = qdrant_client.count(QDRANT_COLLECTION)
        logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {QDRANT_COLLECTION}:")
        logger.info(f"   - –í–µ–∫—Ç–æ—Ä–æ–≤ –≤ –±–∞–∑–µ: {count.count:,}")
        logger.info(f"   - –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {collection_info.config.params.vectors.size}")
        logger.info(f"   - –°—Ç–∞—Ç—É—Å: {collection_info.status}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö –ö–¢–†–£: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")


def analyze_ktru_data(json_file_path):
    """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ö–¢–†–£ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    ktru_data = load_ktru_data_from_json(json_file_path)
    if not ktru_data:
        return

    logger.info("–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ö–¢–†–£...")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    categories = defaultdict(int)
    title_lengths = []
    has_description = 0
    has_attributes = 0

    for entry in ktru_data:
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
        category = extract_category_from_code(entry.get('ktru_code', ''))
        if category:
            categories[category] += 1

        # –î–ª–∏–Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏–π
        title = entry.get('title', '')
        if title:
            title_lengths.append(len(title))

        # –ù–∞–ª–∏—á–∏–µ –æ–ø–∏—Å–∞–Ω–∏–π
        if entry.get('description', '').strip():
            has_description += 1

        # –ù–∞–ª–∏—á–∏–µ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
        if entry.get('attributes', []):
            has_attributes += 1

    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ö–¢–†–£:")
    logger.info(f"   - –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(ktru_data)}")
    logger.info(f"   - –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(categories)}")
    logger.info(f"   - –¢–æ–ø-10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π:")
    for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:10]:
        logger.info(f"     * {cat}: {count} –∑–∞–ø–∏—Å–µ–π")
    logger.info(f"   - –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏—è: {np.mean(title_lengths):.1f} —Å–∏–º–≤–æ–ª–æ–≤")
    logger.info(f"   - –ó–∞–ø–∏—Å–µ–π —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º: {has_description} ({has_description / len(ktru_data) * 100:.1f}%)")
    logger.info(f"   - –ó–∞–ø–∏—Å–µ–π —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏: {has_attributes} ({has_attributes / len(ktru_data) * 100:.1f}%)")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ö–¢–†–£ –∏–∑ JSON-—Ñ–∞–π–ª–∞')
    parser.add_argument('--json_file', type=str, required=True, help='–ü—É—Ç—å –∫ JSON-—Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ –ö–¢–†–£')
    parser.add_argument('--analyze', action='store_true', help='–¢–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏')
    args = parser.parse_args()

    if args.analyze:
        analyze_ktru_data(args.json_file)
    else:
        process_ktru_json(args.json_file)